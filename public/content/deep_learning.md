# How I am learning Deep Learning again

*Written on Aug 22, 2025*

I am going all in. I always never did deep learning seriously. But I am changing it. Over the last 2-3 months, I have been dedicating a lot of time into learning neural nets. This post will go through what I have done, and what I will be doing in the coming few months.

![image](/articleimages/nn.png)

I have done a lot in the past couple of months, and I think it is the right time to talk about my plans. I have taken few ML courses in college, but I was never serious about it. Especially from a research standpoint. I always wanted to build in application layer. And that gave me joy and money.

But I am starting to see the limitations of it wrt what I actually want to do in the long run.

What do I want to do? I wanna build machines which think. Machines which learn, which live. Now this is very diplomatic, and it feels good morally to pursue. But the thing is, end of the day we all gotta pay our bills, and research (for someone in early stage, no academic achievements, not very smart) is not very rewarding in that sense. 

I have a remote job now, where I work on the application layer, which pays me a lot. This job gives me a lot of freedom and time to explore my life and ideas. Hence why I am here, writing blogs, building foundational stuff, and even starting a research "startup".

### Philosophy:
Depth is good. Tearing down abstractions, going all in is the best thing. But it can also waste a lot of time and productivity if you dont do it with a proper structure.

**My learning philosophy:** Cover enough width, then go deep one or two abstractions at a time. Knowing the internals is super important, but that shouldnt stop you from having a complete picture first. 

Hence why, I am covering width. Learning to build models using pytorch. Reading seminal papers chronologically in order to build the same intuition which the current researchers have.

And then, when I have some "free" mindspace, i.e enough knowledge to be confident in building neural models, I am gonna dig deep. Learn the math, learn the GPUs, etc. Everything to give me a better picture. Currently I am 70% there with my knowledge and confidence.

### Importance of goal
For each "phase" of learning, I like to have an end goal. End goals are not something quantitative. They are not supposed to be something which one can measure. Instead they are more about the "vibe". The state of my mind/confidence after I finish a phase. 

This mindset keeps me from overfitting my systems and roadmaps on useless metrics (X hours a day, for Y days).

So the first phase was "Build models with pytorch" and the goal was the same. Being confident in picking up any architecture, and being able to visualize in my mind on how this can be implemented.

### Current Roadmap
Now I hate the word roadmap. Youtube is filled with roadmaps which are completely useless. But I do think, having a plan specifically tailored for your needs is the best roadmap you can follow. This is what I am doing currently.

> IMPORTANT: No course, roadmap, book will be sufficient. Deep learning is a beautiful field of science. It gets better, beautiful (and bigger) the more u dvelve into it

> Note: I am not trying to sell you this roadmap/plan. This blog is about me learning Neural Nets. If you like it, you can modify this to match your needs.

The roadmap I built is not something set in stone. It changes heavily. Thats by nature. As I discover more things, I might refactor this roadmap. 

---

### First Part (Done)
> Goal: To get comfortable with pytorch and NNs.

I did the course by Daniel Bourke on Pytorch. Its a 24 hours course, which gets you at a very good level. I wrote the code by hand, this was painful (How did I survive before Chatgpt) but needed.
Checkout the course: 

Daniel is an amazing person. He was someone I was following since the covid era. Man is really cool.

### Second Part (Ongoing)
> Goal: Build research intuition. To be able to think from the base. First principles

Reading seminal papers chronologically and implementing them. "Reading" can vary heavily. It can be going through the complete paper. It can be just reading the architecture part. Whatever, really doesnt matter. There are no rules. All rules are set by me. More flexibility less friction

### Third Part (Future)
>Goal: I have a vague idea here. To be able to contribute with novel ideas.

Build real foundational models. I have a lot of plans for this, but for now I am fully focussed on the second part.

---


I am doing this in public. You can go through the [repository](https://github.com/theyashwanthsai/Learning-Intelligence). The readme has all the details. It's the best way to go about it. Once I go through the second phase, I am gonna research a lot of subfields. RL, World Models, Language Reasoning. Recently found out mechanistic interpretability, which requires you to have a lot of foundational knowledge.

![image](/articleimages/second_part.png)


Now there is no "timeframe". I dont like to stress myself with deadlines. But I do wanna finish the second phase by the November. Lets see what happens.

I also watch youtube videos from
- https://www.youtube.com/@WelchLabsVideo
- https://www.youtube.com/@RationalAnimations
and many more.

So yea, this is how I am learning neural networks. This field is crazy, and the more I learn, the more I am able to recognize the beauty.